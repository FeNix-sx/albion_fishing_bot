"""
–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∫–ª–µ–≤–∫–∏ –ø–æ –∑–≤—É–∫—É:
1. –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —à–∞–±–ª–æ–Ω–æ–º –∑–≤—É–∫–∞ (template_mono.json)
3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–º–µ–Ω—Ç–∞ –ø–æ–¥—Å–µ—á–∫–∏
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —à—É–º–æ–≤.
"""

import sounddevice as sd
import numpy as np
import librosa
from scipy import signal
import queue
import threading
import time
import pyautogui
import json


class AudioDetectorEnhanced:
    def __init__(self, template_json_path):
        # –ò—â–µ–º VB-CABLE —Å—Ä–µ–¥–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
        devices = sd.query_devices()
        self.device = None

        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                name = device['name'].lower()
                if 'cable' in name or 'vb-audio' in name:
                    self.device = i
                    print(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device['name']}")
                    break

        if self.device is None:
            raise RuntimeError("VB-CABLE –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —à–∞–±–ª–æ–Ω –∏–∑ JSON
        with open(template_json_path, 'r') as f:
            template_data = json.load(f)

        self.template_audio = np.array(template_data['audio'])
        self.template_sample_rate = template_data['sample_rate']
        self.template_mfcc = np.array(template_data['mfcc'])
        self.n_fft = template_data['n_fft']
        self.hop_length = template_data['hop_length']

        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω —à–∞–±–ª–æ–Ω –∏–∑: {template_json_path}")
        print(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —à–∞–±–ª–æ–Ω–∞: {len(self.template_audio) / self.template_sample_rate:.2f} —Å–µ–∫")

        self.audio_queue = queue.Queue()
        self.threshold = 0.5
        self.volume_history = []
        self.detection_buffer = np.array([])
        self.buffer_size = int(self.template_sample_rate * 2)
        self.last_detection_score = 0
        self.max_detection_score = 0
        self.detection_history = []
        self.found_template = False
        self.bite_detected = False
        self.running = False
        self.stream = None
        self.process_thread = None
        self.initialized = False

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞
        # self._print_instructions()

    def _print_instructions(self):
        """–í—ã–≤–æ–¥–∏–º —Å–ø—Ä–∞–≤–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–¥–∏–Ω —Ä–∞–∑"""
        print("\nüé£ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä—ã–±–∞–ª–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞!")
        print("–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:")
        print("–ó–≤—É–∫:   üî¥ –Ω–µ—Ç   üü° —Å–ª–∞–±—ã–π   üü¢ —Ö–æ—Ä–æ—à–∏–π")
        print("–°–∏–≥–Ω–∞–ª: ‚ùå –Ω–µ—Ç   üîç –ø–æ–∏—Å–∫    ‚úÖ –Ω–∞–π–¥–µ–Ω")
        print("–ö–ª—ë–≤:   üé£ –ö–õ–Æ–Å–¢!!! - –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏")
        print("-" * 50)

    def get_volume_indicator(self, volume):
        if volume < 0.05:
            return "üî¥"
        elif volume < 0.2:
            return "üü°"
        else:
            return "üü¢"

    def get_detection_indicator(self, score):
        if score == 0:
            return "‚ùå"
        elif score > self.threshold:
            return "‚úÖ"
        else:
            return "üîç"

    def audio_callback(self, indata, frames, time, status):
        if status:
            print(f"–°—Ç–∞—Ç—É—Å: {status}")
            return

        volume_norm = np.linalg.norm(indata) * 10
        self.volume_history.append(volume_norm)
        self.volume_history = self.volume_history[-10:]

        has_sound = volume_norm > 0.05
        volume_indicator = self.get_volume_indicator(volume_norm)
        detection_indicator = self.get_detection_indicator(self.last_detection_score)

        # print(f"\r–ó–≤—É–∫: {volume_indicator} | "
        #       f"–°–∏–≥–Ω–∞–ª: {detection_indicator} | "
        #       f"–ì—Ä–æ–º–∫–æ—Å—Ç—å: {volume_norm:.2f} | "
        #       f"–°—Ö–æ–∂–µ—Å—Ç—å: {self.last_detection_score:.3f} | "
        #       f"–ú–∞–∫—Å: {self.max_detection_score:.3f}", end='')

        if has_sound:
            # audio_data = indata[:, 0] if len(indata.shape) > 1 else indata  # –ë–µ—Ä—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –ª–µ–≤—ã–π –∫–∞–Ω–∞–ª
            audio_data = np.mean(indata, axis=1) if len(indata.shape) > 1 else indata  # –°—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É L –∏ R
            self.audio_queue.put(audio_data)

    def detect_template_sound(self, audio_data):
        try:
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            mfcc = librosa.feature.mfcc(
                y=audio_data,
                sr=self.sample_rate,
                n_mfcc=13,
                n_fft=self.n_fft,
                hop_length=self.hop_length
            )

            min_width = min(mfcc.shape[1], self.template_mfcc.shape[1])
            mfcc = mfcc[:, :min_width]
            template_mfcc = self.template_mfcc[:, :min_width]

            distance = np.mean(np.abs(mfcc - template_mfcc))
            correlation = signal.correlate(audio_data, self.template_audio, mode='valid')
            correlation_max = np.max(np.abs(correlation))

            detection_score = (1 / (distance + 1e-6)) * correlation_max * 100

            self.last_detection_score = detection_score
            self.max_detection_score = max(self.max_detection_score, detection_score)
            self.detection_history.append(detection_score)
            self.detection_history = self.detection_history[-50:]

            current_volume = np.mean(self.volume_history) if self.volume_history else 0
            return detection_score > self.threshold and current_volume > 6

        except Exception as e:
            print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∑–≤—É–∫–∞: {str(e)}")
            return False

    def initialize(self):
        try:
            if not self.initialized:
                device_info = sd.query_devices(self.device)
                self.sample_rate = int(device_info['default_samplerate'])

                if self.template_sample_rate != self.sample_rate:
                    samples_count = int(len(self.template_audio) * self.sample_rate / self.template_sample_rate)
                    self.template_audio = signal.resample(self.template_audio, samples_count)

                    self.template_mfcc = librosa.feature.mfcc(
                        y=self.template_audio,
                        sr=self.sample_rate,
                        n_mfcc=13,
                        n_fft=self.n_fft,
                        hop_length=self.hop_length
                    )
                    self.template_sample_rate = self.sample_rate

                # print(f"\n–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {device_info['name']}")
                # print(f"–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {self.sample_rate} Hz")
                self.initialized = True
            return True

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
            return False

    def process_audio(self):
        while self.running:
            try:
                new_audio = self.audio_queue.get(timeout=1)

                if len(self.detection_buffer) == 0:
                    self.detection_buffer = new_audio
                else:
                    self.detection_buffer = np.concatenate([self.detection_buffer, new_audio])

                if len(self.detection_buffer) > self.buffer_size:
                    self.detection_buffer = self.detection_buffer[-self.buffer_size:]

                if len(self.detection_buffer) >= len(self.template_audio):
                    if self.detect_template_sound(self.detection_buffer):
                        self.found_template = True
                        self.bite_detected = True
                    else:
                        self.found_template = False

            except queue.Empty:
                continue

    def start(self):
        if not self.initialized:
            if not self.initialize():
                return False

        self.running = True
        self.process_thread = threading.Thread(target=self.process_audio)
        self.process_thread.start()

        try:
            self.stream = sd.InputStream(
                channels=2,
                samplerate=self.sample_rate,
                device=self.device,
                callback=self.audio_callback,
                blocksize=8192
            )
            self.stream.start()
            return True
        except Exception as e:
            print(f"\n–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø–æ—Ç–æ–∫–∞: {str(e)}")
            self.stop()
            return False

    def stop(self):
        self.running = False

        if self.stream is not None:
            self.stream.stop()
            self.stream.close()
            self.stream = None

        if self.process_thread is not None:
            self.process_thread.join()
            self.process_thread = None

        self.last_detection_score = 0
        self.bite_detected = False
        self.found_template = False
        self.detection_buffer = np.array([])
        self.volume_history = []

    def run(self):
        if not self.start():
            return False

        try:
            while self.running:
                time.sleep(0.08)
                if self.last_detection_score > 0.6:
                    print(f"\nüé£ –ö–õ–Æ–Å–¢!!!")
                    self.stop()
                    pyautogui.mouseDown(button='left')
                    time.sleep(0.25)
                    pyautogui.mouseUp(button='left')
                    break

        except KeyboardInterrupt:
            self.stop()
        except Exception as e:
            print(f"\n–û—à–∏–±–∫–∞: {str(e)}")
            self.stop()

        return self.bite_detected


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º–æ –∏–∑ —Ñ–∞–π–ª–∞)
    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞...")
    detector = AudioDetectorEnhanced("template_mono.json")
    detector.run()